{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guoyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "import glob\n",
    "import requests\n",
    "import tarfile\n",
    "import sys\n",
    "import codecs\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import csv\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 docs: 200 train-sentiment, 99 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "os.chdir('H:/GEMINI/Results/WATSON/')\n",
    "f = open('nlp.data.csv', newline = \"\")\n",
    "full = csv.reader(f)\n",
    "full = list(full)\n",
    "\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "alldocs = []\n",
    "for line_no, line in enumerate(full):\n",
    "    tokens = gensim.utils.to_unicode(line[1].lower()).split()\n",
    "    words = tokens[1:]\n",
    "    tags = [line_no]\n",
    "    split = ['train', 'test'][line_no//200]\n",
    "    contrast = line[2]\n",
    "    alldocs.append(SentimentDocument(words, tags, split, contrast))\n",
    "\n",
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "doc_list = alldocs[:]  # for reshuffling per pass\n",
    "\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(doc_list), len(train_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t4)\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t4)\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t4)\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW \n",
    "    Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]\n",
    "\n",
    "# speed setup by sharing results of 1st model's vocabulary scan\n",
    "simple_models[0].build_vocab(alldocs)  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "print(simple_models[0])\n",
    "for model in simple_models[1:]:\n",
    "    model.reset_from(simple_models[0])\n",
    "    print(model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[2]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(train_docs, alpha = 0.1, size = 20, min_alpha = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training epoch 0\n",
      "Now training epoch 20\n",
      "Now training epoch 40\n",
      "Now training epoch 60\n",
      "Now training epoch 80\n",
      "Now training epoch 100\n",
      "Now training epoch 120\n",
      "Now training epoch 140\n",
      "Now training epoch 160\n",
      "Now training epoch 180\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    if epoch % 20 == 0:\n",
    "        print ('Now training epoch %s'%epoch)\n",
    "    model.train\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scanning', 0.9731926918029785),\n",
       " ('administration', 0.9674476981163025),\n",
       " ('following', 0.9669854640960693),\n",
       " ('collimation', 0.9592838287353516),\n",
       " ('intravenously', 0.9511013031005859),\n",
       " ('thorax', 0.9480822086334229),\n",
       " ('5-mm', 0.9443165063858032),\n",
       " ('volumemetric', 0.9365969896316528),\n",
       " ('non-contrast', 0.9362979531288147),\n",
       " ('contrast.comparison', 0.9300181865692139)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"enhanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14848386,  0.26648   ,  0.11515955, -0.55529165,  0.38165605,\n",
       "        0.04689731, -1.03322279,  0.94672775, -0.45723036, -0.12654819,\n",
       "       -0.21645531,  0.44267449,  0.2207628 , -0.37069741, -0.0468344 ,\n",
       "       -0.53290778,  0.19843969, -0.48372751,  0.34176606,  0.73595148], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(test_docs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noncontrast',\n",
       " 'ct',\n",
       " 'thoraxindication',\n",
       " 'aml',\n",
       " 'with',\n",
       " 'neutropenic',\n",
       " 'fever.no',\n",
       " 'previous',\n",
       " 'for',\n",
       " 'comparisonfindings:',\n",
       " 'right',\n",
       " 'tunneled',\n",
       " 'central',\n",
       " 'line',\n",
       " 'in',\n",
       " 'situ',\n",
       " 'with',\n",
       " 'distal',\n",
       " 'tip',\n",
       " 'in',\n",
       " 'the',\n",
       " 'svc.',\n",
       " 'bilateral',\n",
       " 'axillary',\n",
       " 'lymphadenopathy',\n",
       " 'measures',\n",
       " 'up',\n",
       " 'to',\n",
       " '1',\n",
       " 'cm',\n",
       " '.',\n",
       " 'no',\n",
       " 'mediastinal',\n",
       " 'lymphadenopathy',\n",
       " 'identified',\n",
       " 'within',\n",
       " 'the',\n",
       " 'limits',\n",
       " 'of',\n",
       " 'this',\n",
       " 'noncontrast',\n",
       " 'study.',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'small',\n",
       " 'pericardial',\n",
       " 'effusion.',\n",
       " 'no',\n",
       " 'pleural',\n",
       " 'effusions.',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'mildly',\n",
       " 'enlarged',\n",
       " 'for',\n",
       " 'age.limited',\n",
       " 'unenhanced',\n",
       " 'images',\n",
       " 'of',\n",
       " 'the',\n",
       " 'upper',\n",
       " 'abdomen',\n",
       " 'reveal',\n",
       " 'hepatosplenomegaly.',\n",
       " 'no',\n",
       " 'airspace',\n",
       " 'consolidation',\n",
       " 'or',\n",
       " 'pulmonary',\n",
       " 'nodules',\n",
       " 'identified.',\n",
       " 'there',\n",
       " 'is',\n",
       " 'linear',\n",
       " 'band',\n",
       " 'atelectasis',\n",
       " 'within',\n",
       " 'the',\n",
       " 'apical',\n",
       " 'segment',\n",
       " 'of',\n",
       " 'the',\n",
       " 'right',\n",
       " 'lower',\n",
       " 'lobe',\n",
       " 'medially',\n",
       " 'and',\n",
       " 'at',\n",
       " 'the',\n",
       " 'right',\n",
       " 'lung',\n",
       " 'base',\n",
       " 'medial',\n",
       " 'basal',\n",
       " 'segment.',\n",
       " 'there',\n",
       " 'is',\n",
       " 'mosaic',\n",
       " 'attenuation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'parenchyma',\n",
       " 'for',\n",
       " 'example',\n",
       " 'some',\n",
       " 'peripheral',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'lucent',\n",
       " 'lung',\n",
       " 'at',\n",
       " 'the',\n",
       " 'bases',\n",
       " 'on',\n",
       " 'image',\n",
       " '62',\n",
       " 'in',\n",
       " 'keeping',\n",
       " 'with',\n",
       " 'a',\n",
       " 'air',\n",
       " 'trapping',\n",
       " 'from',\n",
       " 'small',\n",
       " 'airways.no',\n",
       " 'suspicious',\n",
       " 'bone',\n",
       " 'lesion',\n",
       " 'identified.conclusion:no',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'pneumonia',\n",
       " 'or',\n",
       " 'pulmonary',\n",
       " 'infectious',\n",
       " 'process.mild',\n",
       " 'cardiomegaly',\n",
       " 'for',\n",
       " 'the',\n",
       " \"patient's\",\n",
       " 'age',\n",
       " 'with',\n",
       " 'a',\n",
       " 'small',\n",
       " 'pericardial',\n",
       " 'effusion.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
