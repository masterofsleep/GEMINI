{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import sys\n",
    "import codecs\n",
    "import gensim\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import sklearn\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('H:/GEMINI/Results/WATSON/')\n",
    "f = open('nlp.data.csv', newline = \"\")\n",
    "full = csv.reader(f)\n",
    "full = list(full)\n",
    "full = full[1:]\n",
    "\n",
    "alldocs = []\n",
    "for line_no, line in enumerate(full):\n",
    "    words = gensim.utils.to_unicode(line[1].lower()).split()\n",
    "    tags = [line_no]\n",
    "    contrast = [line[2]]\n",
    "    alldocs.append(gensim.models.doc2vec.TaggedDocument(words, tags))\n",
    "\n",
    "#train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "#test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "#doc_list = alldocs[:]  # for reshuffling per pass\n",
    "\n",
    "#print('%d docs: %d train-sentiment, %d test-sentiment' % (len(doc_list), len(train_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm = gensim.models.Doc2Vec(alpha = 0.1, size = 20, min_alpha = 0.025, iter= 10, min_count = 3, window = 10)\n",
    "model_dbow = gensim.models.Doc2Vec(alpha = 0.1, size = 20, min_alpha = 0.025, iter= 10, min_count = 13, window = 10, dm= 0)\n",
    "model_dm.build_vocab(alldocs)\n",
    "model_dbow.build_vocab(alldocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must specify either total_examples or total_words, for proper alpha and progress calculations. The usual value is total_examples=model.corpus_count.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-528-ea2a5c34a39e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malldocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_dm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malldocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_dbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malldocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#for epoch in range(len(alldocs)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\guoyi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtotal_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You must specify either total_examples or total_words, for proper alpha and progress calculations. The usual value is total_examples=model.corpus_count.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You must specify an explict epochs count. The usual value is epochs=model.iter.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You must specify either total_examples or total_words, for proper alpha and progress calculations. The usual value is total_examples=model.corpus_count."
     ]
    }
   ],
   "source": [
    "random.shuffle(alldocs)\n",
    "model_dm.train(alldocs)\n",
    "model_dbow.train(alldocs)\n",
    "\n",
    "#for epoch in range(len(alldocs)):\n",
    "#    if epoch % 20 == 0:\n",
    "#        print ('Now training epoch %s'%epoch)\n",
    "#    model.train\n",
    "    #model.alpha -= 0.002  # decrease the learning rate\n",
    "    #model.min_alpha = model.alpha  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['chest', 'ct', 'enhanced', '2.5', 'mm', 'axial', 'images', 'every', '2', 'mm', 'were', 'obtained', '(', 'with', 'sagittal', 'and', 'coronal', 'reformats', ')', 'with', '50%', 'overlap', 'and', 'compared', 'to', 'the', 'study', 'obtained', 'in', 'september,', '2013.', 'there', 'is', 'no', 'significant', 'change', 'in', 'the', 'moderate', 'to', 'large', 'right', 'pleural', 'effusion.', 'there', 'is,', 'however,', 'a', 'new', 'smaller', 'left', 'effusion.', 'there', 'are', 'multiple', 'foci', 'of', 'groundglass/interstitial', 'thickening,', 'mainly', 'peripheral', 'and', 'most', 'pronounced', 'in', 'the', 'left', 'upper', 'lobe', '(', 'e.g.', 'image', '72', 'and', 'coronal', 'image', '78', ').', 'these', 'are', 'similar', 'to', 'the', 'september', 'study', 'but', 'more', 'pronounced.', 'similar', 'findings', 'at', 'the', 'left', 'base', 'adjacent', 'to', 'the', 'small', 'effusion', '(', 'e.g.', 'image', '95', ')', 'look', 'similar', 'to', 'the', 'previous', 'study.', 'there', 'is', 'also', 'some', 'subpleural', 'reticulation,', 'best', 'appreciated', 'in', 'the', 'right', 'upper', 'lobe-unchanged.', 'minor', 'passive', 'crowding/atelectasis', 'in', 'both', 'lower', 'lobes.', 'right', 'axillary', 'nodes', 'have', 'decreased', 'in', 'size,', 'now', 'normal.', 'no', 'mediastinal', 'or', 'supraclavicular', 'adenopathy.', 'normal', 'heart', 'size.', 'stable', 'small', 'pericardial', 'effusion.', 'heavily', 'calcified', 'coronary', 'arteries.', 'although', 'overall', 'heart', 'size', 'is', 'normal,', 'the', 'atrium', 'are', 'slightly', 'enlarged.', 'the', 'esophagus', 'look', 'somewhat', 'thickwalled,', 'but', 'unchanged-and', 'not', 'dilated.', 'normal', 'thyroid.', 'normal', 'central', 'airways.', 'there', 'is', 'a', 'small', 'amount', 'of', 'free', 'fluid', 'around', 'the', 'liver.', 'no', 'concerning', 'bony', 'findings.', 'opinion:', 'stable', 'moderate/large', 'right', 'pleural', 'effusion', 'and', 'new', 'small', 'left', 'effusion.', 'the', 'parenchymal', 'opacities', 'are', 'nonspecific.', 'they', 'are', 'slightly', 'more', 'pronounced', 'than', 'in', 'september', 'and', 'could', 'be', 'due', 'to', 'either', 'focal', 'edema', 'or', 'low-level', 'activity', 'inflammatory', 'change.', '_____________', 'this', 'report', 'was', 'electronically', 'signed', 'by', 'shulman,', 'harry', 's.,', 'staff', 'radiologist', 'on', '2014/05/21', 'at', '10:21'], tags=[52])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldocs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_dbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "word_vec = []\n",
    "label = []\n",
    "for i in range(len(full)):\n",
    "    word_vec.append(model.infer_vector(full[i][1]))\n",
    "    label.append(full[i][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(C=1e5, penalty = \"l1\", n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticmodel = log_model.fit(X = word_vec[:200], y = label[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62244897959183676"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.score(word_vec[200:], label[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.602564102564\n",
      "Linear SVM 0.628205128205\n",
      "RBF SVM 0.628205128205\n",
      "Gaussian Process 0.628205128205\n",
      "Decision Tree 0.564102564103\n",
      "Random Forest 0.5\n",
      "Neural Net 0.628205128205\n",
      "AdaBoost 0.538461538462\n",
      "Naive Bayes 0.564102564103\n",
      "QDA 0.589743589744\n"
     ]
    }
   ],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(20),\n",
    "    SVC(kernel=\"linear\", C=1),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=10, max_features=3),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "X_train, X_test, y_train, y_test = word_vec[:220], word_vec[220:], label[:220], label[220:]\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(name,  score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
